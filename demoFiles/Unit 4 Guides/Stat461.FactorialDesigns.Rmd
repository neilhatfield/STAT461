---
title: "Factorial Models"
author: "Neil J. Hatfield"
date: "4/15/2022"
output: 
  pdf_document
geometry: left=0.5in,right=0.5in,top=0.5in,bottom=0.5in
urlcolor: blue
header-includes: 
  \usepackage{subfig}
---

```{r setupFiles, echo=FALSE, include = FALSE}
# Setting Document Options
knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE,
  message = FALSE,
  fig.align = "center"
)

packages <- c("tidyverse", "knitr", "kableExtra",
              "parameters", "hasseDiagram", "car",
              "psych", "DescTools", "emmeans")
lapply(packages, library, character.only = TRUE)

options(knitr.kable.NA = "")
options(contrasts = c("contr.sum", "contr.poly"))

source("https://raw.github.com/neilhatfield/STAT461/master/rScripts/ANOVATools.R")

```

In this tutorial, we are going to explore Factorial Treatment Structures/Factorial Designs in R. For our purposes here, we will restrict our attention to [full] factorial models with all Fixed Factor Effects. (We will allow for our measurement units to be the only random effect term.) The general structure for this guide will be:

+ Setting Up R
  - Loading Packages, Setting Options, and Additional Tools
+ Data Contexts
  - Load! Aim! Ready! Release! (Gummy Bear Catapult)
  - Battery Manufacturing
+ Exploring the Factorial Treatment Structure
+ Fit the Models
  - Appropriateness of ANOVA
  - Check Interactions
  - Form the Model
+ Assessing Assumptions
  - Gaussian Residuals
  - Homoscedasticity
  - Independence of Observations
+ Results
  - Omnibus
  - Point Estimates
  - Post Hoc--Pairwise
  - Post Hoc--Contrasts
  - Effect Sizes
+ Dealing with Imbalanced Designs

# Setting Up R

Just as in the prior guides/tutorials, we have to first ensure that `R` is properly configured and prepared for our work. We will want to ensure that we load all of the appropriate packages, set our constraint, and load in any additional tools. 

I've also added in the `psych` package to demonstrate an approach you can use for getting values of descriptive statistics in accordance with the factorial treatment structure. You'll also see the `openxlsx` package in the list; this happens to be my preferred way to read in XLSX files.

As a reminder, the following code does all of these things:

```{r setR, echo=TRUE, eval=FALSE}
# Demo code to set up R
## Load packages
packages <- c("tidyverse", "knitr", "kableExtra",
              "parameters", "hasseDiagram", "car",
              "psych", "DescTools", "emmeans",
              "openxlsx")
lapply(packages, library, character.only = TRUE)

## Set options and constraint
options(knitr.kable.NA = "")
options(contrasts = c("contr.sum", "contr.poly"))

## Load useful tools
source("https://raw.github.com/neilhatfield/STAT461/master/rScripts/ANOVATools.R")

```

# Data Contexts

For this guide/tutorial, we'll make use of two contexts: __Load! Aim! Ready! Release! (Gummy Bears)__ and __Battery Manufacturing (Batteries)__.

## Load! Aim! Ready! Release! (Gummy Bears)

This data comes from the design that we put together in class to explore the impacts of launch angle and launch position for our spoon-apults for launching gummy bears to see how far they will fly.

```{r loadGummyBears, echo=TRUE}
# Demo code for loading and cleaning data
## Loading gummy bear data
catapultData <- openxlsx::readWorkbook(
  xlsxFile = "https://raw.github.com/neilhatfield/STAT461/master/dataFiles/gummyBears2022.xlsx",
  sheet = 1,
  colNames = TRUE,
  rowNames = FALSE
)

## Change variables
names(catapultData)[which(names(catapultData) == "Launch.Angle")] <- "Angle"
names(catapultData)[which(names(catapultData) == "Launch.Position")] <- "Position"
names(catapultData)[which(names(catapultData) == "Measurement.Order")] <- "Order"

## Fix the data
## R will treat high and High as TWO separate levels
## Same with low & Low, back & Back, and front & Front
catapultData <- catapultData %>%
  dplyr::mutate(
    Angle = dplyr::recode_factor(
      Angle,
      "high" = "High", # Old Value = New Value
      "High" = "High",
      "low" = "Low",
      "Low" = "Low"
    ),
    Position = dplyr::recode_factor(
      Position,
      "back" = "Back",
      "Back" = "Back",
      "front" = "Front",
      "Front" = "Front"
    ),
    ## This is optional but I'm going to standardize team names
    Team = dplyr::case_when(
      !grepl(pattern = "Team", Team) ~ paste("Team", Team),
      TRUE ~ Team
    )
  )

```

Notice that I used a couple of functions from `dplyr` to help me clean and take control of the data. The `mutate` function allows you to change an entire column of a data frame in a consistent and relatively speedy way. The `recode_factor` function combines two things: alter values for consistency AND tell `R` to treat the attribute as a factor. Note: the order you list the new values will be the order `R` uses for the factor levels.

## Battery Manufacturing

An engineer is designing a battery for use in a device that will people will use in some extreme temperatures. Unfortunately, the engineer may only alter one design parameter: the plate material for the battery of which he has three choices.

The device his batteries are for gets manufactured separately and is then shipped to the field, where the engineer has no control over the temperature the device will encounter. His experiences lead him to believe that environmental temperature will affect the battery life. He can control the temperature in the lab for product development testing.

He decides to test all three plate materials at three temperature levels—15ºF, 70ºF, and 125ºF—as these temperatures are consistent with reported end-use environments.

His questions:

1) What effects do material type and temperature have on life of battery?
2) Is there a choice of material that would give uniformly long life regardless of temperature?

```{r loadBattery, echo=TRUE}
## Demo code for loading and cleaning data
## Load battery data
batteryData <- read.table(
  file = "https://raw.github.com/neilhatfield/STAT461/master/dataFiles/batteryLife.dat",
  header = TRUE,
  sep = ","
)

## Clean data
batteryData$temperature <- dplyr::recode_factor(
  batteryData$temperature,
  `15` = "15ºF",
  `70` = "70ºF",
  `125` = "125ºF"
)
batteryData$material <- dplyr::recode_factor(
  batteryData$material,
  `1` = "Plate 1",
  `2` = "Plate 2",
  `3` = "Plate 3"
)

```

# Exploring the Factorial Treatment Structure

Exploring the data in factorial settings becomes much more important as now you have many more ways to think about slicing up the data resulting in more ways to help people (and yourself) think about the data. Remember, data visualizations are some of your strongest and most helpful tools here. 

## Box Plots Revisited

You can use the multiple factors in a variety of ways in your data visualizations. For example, rather than looking at a side-by-side box plots along one factor, you could do a set for each factor or by the interaction. R's base `boxplot` function allows for you explore interactions by using the formula argument.

```{r interactionBoxplot, fig.cap="Box Plot of Battery Life Spans by Temperature and Plate Material", fig.width=7, fig.height=5, echo=TRUE, fig.pos="H"}
# Demo code for box plots using factorial treatment structure
## Battery Manufacturing
boxplot(
  formula = life ~ temperature:material,
  data = batteryData,
  ylab = "Life (hrs)",
  xlab = "Temp (ºF) x Material"
)

```

While this box plot is okay to look at, we could improve this plot greatly for professional work. The easiest method would be to use `ggplot2`.

```{r boxplots2, echo=TRUE, fig.cap="Box Plot With Multiple Factors--Gummy Bears Study", fig.width=6, fig.height=3, fig.pos="H"}
# Demo code of box plots incorporating factorial treatment structure
## ggplot2 and Gummy Bears Study
ggplot(
  data = catapultData,
  mapping = aes(
    x = Angle,
    y = Distance,
    fill = Position
  )
) +
  geom_boxplot() +
  theme_bw() +
  xlab("Launch Angle") +
  ylab("Distance (in)") +
  labs(
    fill = "Launch Position"
  ) +
  theme(
    legend.position = "right",
    text = element_text(size = 14)
  )

```

## Descriptive Statistics

In addition to data visualizations, we also may make use of descriptive/incisive statistics. We've used the `describeBy` from the `psych` package in the past to break our response up into groups based upon our factor. We can do something similar in multi-factor situations as shown here:

```{r descStatsBattery, echo=TRUE}
# Demo code for descriptive statistics for factorial treatment structure
## Battery Manufacturing 
batteryStats <- psych::describeBy(
  x = batteryData$life,
  # Notice how we're getting the factorial treatments
  group = paste(batteryData$temperature, batteryData$material, sep = " x "),
  na.rm = TRUE,
  skew = TRUE,
  ranges = TRUE,
  quant = c(0.25, 0.75),
  IQR = TRUE,
  mat = TRUE,
  digits = 4
)

batteryStats %>%
  tibble::remove_rownames() %>%
  tibble::column_to_rownames(
    var = "group1"
  ) %>%
  dplyr::select(
    n, min, Q0.25, median, Q0.75, max, mad, mean, sd, skew, kurtosis
  ) %>%
  knitr::kable(
    caption = "Summary Statistics for Battery Life Spans",
    digits = 3,
    format.args = list(big.mark = ","),
    align = rep('c', 11),
    col.names = c("n", "Min", "Q1", "Median", "Q3", "Max", "MAD", "SAM", "SASD",
                  "Sample Skew","Sample Ex. Kurtosis"),
    booktabs = TRUE
  )  %>%
  kableExtra::kable_styling(
    font_size = 12,
    latex_options = c("HOLD_position", "scale_down")
  ) 

```

If you are using `dplyr`'s `summarize` function, you can achieve similar results by first calling `group_by` and then listing all of your factors. In this case we would want `dplyr::group_by(temperature, material)`.

```{r descStatsGummyBears, echo=TRUE}
# Demo code for descriptive statistics for factorial treatment structure
## Gummy Bears 
catapultData %>%
  dplyr::group_by(Angle, Position) %>%
  summarize(
    n = n(),
    min = min(Distance),
    Q1 = quantile(Distance, probs = c(0.25)),
    med = median(Distance),
    Q3 = quantile(Distance, probs = c(0.75)),
    max = max(Distance),
    mad = mad(Distance),
    sam = mean(Distance),
    sd = sd(Distance),
    skew = psych::skew(Distance),
    kurtosis = psych::kurtosi(Distance)
  ) %>%
  knitr::kable(
    caption = "Summary Statistics for Gummy Bear Study",
    digits = 3,
    format.args = list(big.mark = ","),
    align = rep('c', 13),
    col.names = c("Angle", "Position", "n", "Min", "Q1", "Median", "Q3", "Max", "MAD",
                  "SAM", "SASD", "Sample Skew","Sample Ex. Kurtosis"),
    booktabs = TRUE
  )  %>%
  kableExtra::kable_styling(
    font_size = 12,
    latex_options = c("HOLD_position", "scale_down")
  ) 

```

Either approach (`psych::describeBy` or `dplyr::group_by` and `dplyr::summarize`) works for getting values of descriptive statistics in accordance to the factorial treatment structure.

# Fit the Models

Before we write code to fit the factorial model in `R`, we should do two things: 1) double check that a factorial ANOVA approach is appropriate, and 2) check for interactions.

## Appropriateness of ANOVA

As we have been doing since Unit 3, checking for whether ANOVA methods are appropriate for answering our SRQ comes down to the following:

+ Do we have a quantitative response?
+ Do we have two or more categorical/qualitative factors? (If only one, then we're not factorial ANOVA.)
+ Do we have enough *Degrees of Freedom* to be able to estimate the Main Effects and Interactions?
+ Do we have enough *Degrees of Freedom* for estimating residuals/errors?
+ (For Main Effects Only Models: do we have an additive model?)

As before, our knowledge of the study design and the Hasse diagram can help us out.

Figure \ref{fig:batteriesHD} shows the Hasse diagram for the Battery Manufacturing study. We know that the response is quantitative (number of hours of life). From the Hasse diagram, we have two factors (Plate Material and Temperature) which are both categorical. We are doing a full factorial structure (we have all possible interactions). Further, since we have positive *Degrees of Freedom* for each node in the Hasse diagram, we know that we should be able to estimate all main effects, interactions, and the residuals/errors.

```{r batteriesHD, fig.cap="Hasse Diagram for Battery Manufacturing Study", fig.height=2, fig.pos="H"}
# Hasse Diagram
modelLabels <- c("1 Maintain Charge 1", "3 Plate 2", "3 Temperature 2",
                 "9 Plate × Temperature 4", "36 (Batteries) 27")
modelMatrix <- matrix(
  data = c(FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, TRUE,
           FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE, FALSE, FALSE, TRUE, TRUE,
           TRUE, TRUE, FALSE),
  nrow = 5,
  ncol = 5,
  byrow = FALSE
)
hasseDiagram::hasse(
 data = modelMatrix,
 labels = modelLabels
)

```

### Your Turn

Create a similar paragraph as I did but for the Gummy Bears situation.

## Check Interactions

With a [Full] Factorial Design, we no longer have a truly additive model. The interaction term, in some ways, is a measure of how far our model departs from additivity. We want to see whether interactions are important or unimportant: data visualizations are our key to detect this. However, unlike with One-way ANOVA with a Block, we will not worry if we see interactions.

There are several ways that we can look at interaction plots. In the guide/tutorial on Block designs, we saw a way that we can use the `ggplot2` package to create an interaction plot. However, there is also a method that uses Base `R` (i.e., no extra packages).

### Base `R` Interaction Plot 

The function `interaction.plot` is part of the basic setup of `R` (included in the default `stats` package). This function allows us to explore the interaction between __TWO__ factors at a time. This does mean that if you want to try to explore a three-way interaction, this method won't work. 

```{r batteryInt1, fig.cap="Interaction Plot using base R", fig.width=6, fig.height=3.5, echo=TRUE, fig.pos="H"}
# Demo code for using base R to create an interaction plot
## Battery Manufacturing Study
interaction.plot(
  x.factor = batteryData$temperature, # First Factor
  trace.factor = batteryData$material, # Second Factor
  response = batteryData$life, # Response
  fun = mean,
  type = "b", # Both points and lines
  col = c("black","red","blue"), # Set colors for trace
  pch = c(19, 17, 15),  # Set symbols for trace
  fixed = TRUE,
  legend = TRUE,
  xlab = "Operating Temperature",
  ylab = "Life Span (hours)",
  trace.label = "Plate Material")

```

For a plot from base `R`, this is actually a pretty decent. Remember, we're looking to see if as we move through the levels of one factor (operating temperature) and through the levels of the other factor (plate material), what appears to be happening to the response (life span). If there is no interaction, then we should see consistent behaviors throughout (perfect world of no interaction would have parallel line segments). The more inconsistent the behavior (for example, complete reversal of behavior, perpendicular line segments), the more impactful the interaction is between the two factors

#### Example Write up

From Figure \ref{fig:batteryInt1}, we can see that there is some interaction between the operating temperature and plate material. For example, going from 15ºF to 70ºF, produced a drop in life span for materials one and two but for plate three there is a slight increase in life span. As we move from room temperature (70ºF) to the high of 125ºF, this time plate material one appears to hold steady in life span while the other two materials experience drops in life span.

### Using `ggplot2` for Interaction Plots

As we saw in the Block guide/tutorial, we can use `ggplot2` to create an interaction plot. Again, you want to have some care here for how many factors you want to explore at any one time. With `ggplot2` you can move beyond two factors at a time, but be careful; you don't want to overwhelm your audience.

In the following example, I'm going to create an interaction plot for launch angle and launch position, but I'm also going to place the observations on the graph so we can also get a sense of variation that gets hidden by the trend lines.

```{r catapultInteraction1, fig.cap="Interaction Plot for Gummy Bears Study", fig.width=6, fig.height=3.5, echo=TRUE, fig.pos="H"}
# Demo code for using ggplot to make interaction plot w/observations showing
## Gummy Bears Study
ggplot(
  data = catapultData,
  mapping = aes(
    x = Angle,
    y = Distance,
    shape = Position,
    color = Position,
    linetype = Position,
    group = Position
  )
) +
  stat_summary(fun = "mean", geom = "point", size = 3) +
  stat_summary(fun = "mean", geom = "line", size = 1) +
  geom_jitter(width = 0.1, height = 0.1, alpha = 0.25, size = 1) +
  ggplot2::theme_bw() +
  xlab("Launch Angle") +
  ylab("Distance (in)") +
  labs(
    color = "Launch Position",
    shape = "Launch Position",
    linetype = "Launch Position"
  ) +
  scale_color_manual(values = c("red", "blue")) +
  theme(
    legend.position = "bottom",
    text = element_text(size = 12)
  )

```

Whether you use the interaction plot code laid out in the Block guide/tutorial, the base `R` approach, or this most recent version is entirely up to you. What you want to be sure of is that the visualization helps you and your audience gain a deeper understanding of the data and context for the SRQ. You also want to make sure that the data visualization looks good.

### Your Turn

Write up a paragraph that goes with Figure \ref{fig:catapultInteraction1}.

## Form the Model

Once we've verified that a factorial ANOVA model is appropriate and made a decision about including interaction terms\footnote{There is no harm in keeping interaction terms in the model, even if you don't think there is an interaction...provided you have sufficient \textit{Degrees of Freedom}.}, we can turn our attention to forming the model in `R`.

There are a couple of different ways that you can specify factorial designs in `R`: you can manually type in the main the effects and interactions in the order you wish OR you can let `R` fill in all of the terms for you. 

For `R`, to specify a main effect, you simply type the name of the factor in the formula just as we have been doing all semester.

For an interaction, you'll type the names of __all__ main effects involved in the interaction, separating each name with a colon (:). For example, if we wanted the two-way interaction of A and B, we would type `A:B`; for a three-way interaction of A, B, and C, we would type `A:B:C`.

To have `R` automatically fill in all terms, you simply list each main effect and use `*` to separate terms. Thus, typing `y ~ A*B` is the same as `y ~ A + B + A:B`. Notice that in the `formula` argument the `*` symbol can take on multiple meanings: multiplication as in `2*A` and factorial expansion as in `A*B` going to `A + B + A:B`. 

I'll show both approaches here:

```{r factorialModels, echo=TRUE}
# Demo code for forming the factorial models
## Fitting by hand--Battery Manufacturing Study
batteryModel <- aov(
  formula = life ~ temperature + material + temperature:material,
  data = batteryData
)

## Letting R handle the expansion--Gummy Bears Study
catapultModel <- aov(
  formula = Distance ~ Angle*Position,
  data = catapultData
)

```


# Assessing Assumptions

For the parametric shortcut for factorial designs (the ANVOA *F* test), we have the same three assumptions as in the One-way case: Gaussian Residuals, Homoscedasticity, and Independence of Observations. We will assess them in the same ways as we have before.

## Gaussian Residuals

Use a QQ plot like usual:

```{r residualQQ, fig.cap="QQ Plot for Residuals in Battery Manufacturing Study", fig.width=5, fig.height=3.5, echo=TRUE, fig.pos="H"}
# Demo code for QQ plot
# Battery Manufacturing
car::qqPlot(
  x = residuals(batteryModel), 
  distribution = "norm",
  envelope = 0.90,
  id = FALSE,
  pch = 20,
  ylab = "Residuals (hours)"
)

```

There is very little to be concerned about in our QQ plot; we will go ahead and proceed as if our residuals follow a Gaussian distribution.

### Your Turn

Build a QQ plot and write accompanying text for assessing the Gaussian Residuals assumption for the Gummy Bears Study.

## Homoscedasticity

Just as in the One-way ANOVA with a Block, we will want to look at a Tukey-Anscombe plot rather than a strip chart for our factorial designs.

```{r batteryVar, fig.cap="Tukey-Anscombe Plot for Battery Manufacturing Study", fig.width=4, fig.height=3, echo=TRUE, fig.pos="H"}

ggplot(
  data = data.frame(
    residuals = residuals(batteryModel),
    fitted = fitted.values(batteryModel)
  ),
  mapping = aes(x = fitted, y = residuals)
) +
  geom_point(size = 2) +
  geom_hline(
    yintercept = 0,
    linetype = "dashed",
    color = "grey50"
  ) +
  geom_smooth(
    formula = y ~ x,
    method = stats::loess,
    method.args = list(degree = 1),
    se = FALSE,
    size = 0.5
  ) +
  theme_bw() +
  xlab("Fitted values (hours)") +
  ylab("Residuals (hours)")

```

The first thing that I notice in the Tukey-Anscombe plot (Figure \ref{fig:batteryVar}) is that the fourth strip from the left shows the least amount of variation while the fifth strip (from the left) shows the most. The fifth used more than twice the vertical space as the fourth, however, this is the only aspect that causes me a moment of hesitation. There are no discernible patterns to the plot and the blue reference line is perfectly horizontal indicating that we have [sufficient] homoscedasticity.

## Independence of Observations

For Independence of Observations, keep in mind that our Go To is to think about the study design. If we happen to know measurement order, then we can make use of an index plot and the DW statistic.

### Battery Manufacturing Study

Unfortunately, we don't know measurement order in the Battery Manufacturing study, so index plots are not going to be useful here. However, we can think through the study design and reach a decision about independent observations.

In this particular case, we know that the the application of plate material was randomly assigned to instances of battery building process and that a set of batteries using each plate material were selected via a random process. Within each of those sets, the engineer assigned an operating temperature to each battery. Taken together, this information does not raise any flags that we have dependent observations based upon the design.

### Gummy Bears Study





+ Results
  - Omnibus
  - Point Estimates
  - Post Hoc--Pairwise
  - Post Hoc--Contrasts
  - Effect Sizes
+ Dealing with Imbalanced Designs



#

## Results

Remember, there are essentially two parts to results: the omnibus test and the post hoc analysis.

### Omnibus Results

In this particular situation, we have a __balanced__ design, thus we do not need to worry about different types of Sums of Squares.

```{r barleyTable, echo=TRUE}
# Omnibus Test/Modern ANOVA Table
parameters::model_parameters(
    model = batteryModel,
    omega_squared = "partial",
    eta_squared = "partial",
    epsilon_squared = "partial"
) %>%
  knitr::kable(
    digits = 4,
  col.names = c("Source", "SS", "df", "MS", "F", "p-value",
                "Partial Omega Sq.", "Partial Eta Sq.", "Partial Epsilon Sq."),
  caption = "ANOVA Table for Batter Life Span Study",
  align = c('l',rep('c',8)),
  booktab = TRUE
) %>%
  kableExtra::kable_styling(
    bootstrap_options = c("striped", "condensed"),
    font_size = 12,
    latex_options = c("scale_down", "HOLD_position")
  )

```

We treat this type just like we have before, except that now we're interested in __ALL__ of the rows and thus we will need to talk about each of the main effects and interactions. The partial effect sizes are still interpreted as proportion of the variation in the response by just that main effect/interaction (all others are dropped).

### Post Hoc Analysis

#### Point Estimates

I want to quickly remind you that you can get point estimates for your main effects and treatment effects using the `dummy.coef` function. If you need confidence intervals for these, you can use the `confint` function (don't forget to provide an *adjusted* confidence level).

```{r batteryPointEstimates, echo=TRUE}
# Point Estimates for Battery Factorial Model
## Don't use raw output in your reports, make a nice table
dummy.coef(batteryModel)

```


#### Pairwise Comparisons

While you *could* use the pairwise comparison functions we've previously used, a better approach is to embrace our Factorial Design and look at the *estimated marginal means*. These will hold certain factors constant and let others vary. To do this, we will need to use the `emmeans` package.

```{r batteryPH1, echo=TRUE}
# Pairwise Comparisons
batteryPH <- emmeans::emmeans(
  object = batteryModel,
  # The order of factors does not really matter
  specs = pairwise ~ temperature | material,
  adjust = "tukey",
  level = 0.9
)

as.data.frame(batteryPH$emmeans) %>%
  knitr::kable(
    digits = 4,
    col.names = c("Temperature", "Plate Material", "Marginal Mean","SE", "DF",
                  "Lower Bound","Upper Bound"),
    caption = "Marginal Means-Tukey 90\\% Adjustment",
    align = c("l","l", rep("c", 5)),
    booktabs = TRUE
  ) %>%
  kableExtra::kable_styling(
    bootstrap_options = c("striped", "condensed"),
    font_size = 12,
    latex_options = c("scale_down", "HOLD_position")
  )

```

The `adjust` argument of `emmeans` allows for the following values for confidence intervals: `"bonferroni"`, `"tukey"`, `"scheffe"`, and `"sidak"`. If you do not want confidence intervals you may use values of `"holm"`, `"hochberg"`, `"hommel"`, `"BH"` (Benjamini and Hochberg), and `"fdr"`.

### Effect Sizes

Unfortunately, my `anova.PostHoc` function does not currently work with with factorial models. However, the `emmeans` package provides us with a way to get Cohen's *d*, which then allows us to my `probSup` function to get the Probability of Superiority.

```{r effectSize1, echo=TRUE}
# We want to first narrow our focus and store the marginal means
## You could change the specs to material
tempEMM <- emmeans::emmeans(
  object = batteryModel,
  specs = "temperature"
)

# Pass the stored marginals into the effect size function
cohenTemp <- emmeans::eff_size(
  object = tempEMM,
  sigma = sigma(batteryModel),
  edf = df.residual(batteryModel)
)

# Create a data frame, add on the probability of superiority
# Send that data frame into a nice table
as.data.frame(cohenTemp) %>%
  dplyr::mutate(
    ps = probSup(effect.size),
    .after = effect.size
  ) %>%
  dplyr::select(contrast, effect.size, ps) %>%
  knitr::kable(
    digits = 3,
    col.names = c("Comparison", "Cohen's d", "Probability of Superiority"),
    align = "lcc",
    caption = "Effect Sizes for Temperature",
    booktab = TRUE
  ) %>%
  kableExtra::kable_styling(
    bootstrap_options = c("striped", "condensed"),
    font_size = 12,
    latex_options = "HOLD_position"
  )

## Doing the same for material
matEMM <- emmeans::emmeans(
  object = batteryModel,
  specs = "material"
)
cohenMat <- emmeans::eff_size(
  object = matEMM,
  sigma = sigma(batteryModel),
  edf = df.residual(batteryModel)
)

as.data.frame(cohenMat) %>%
  dplyr::mutate(
    ps = probSup(effect.size),
    .after = effect.size
  ) %>%
  dplyr::select(contrast, effect.size, ps) %>%
  knitr::kable(
    digits = 3,
    col.names = c("Comparison", "Cohen's d", "Probability of Superiority"),
    align = "lcc",
    caption = "Effect Sizes for Material",
    booktab = TRUE
  ) %>%
  kableExtra::kable_styling(
    bootstrap_options = c("striped", "condensed"),
    font_size = 12,
    latex_options = "HOLD_position"
  )

```

# Imbalanced Designs

As mentioned in class, when you have imbalanced designs for factorial models, we have to make a decision about which type of Sums of Squares we want to use.

## Type I Sums of Squares--Sequential

If you really want Type I SSQs in a factorial setting (which is often not consistent with most typical SRQs), then you do not need to do anything different than what you have. Just make sure that your `formula` argument of the `aov` call is in the order you want. (Note: I recommend manually entering the model rather than letting R automatically fill in the formula whenever you might have the tinest bit of hestiation over what your model is.)

## Type II and Type III Sums of Squares

The vast majority of the time, SRQs for factorial designs revolve around Type II (for model building) and Type III (for testing differences in factor levels) Sums of Squares. To get these sums of squares, I recommend using the `car` package's `Anova` function.

For this example, I'm going to use a data set on different training methods' (fixed, 2 levels) and engery drink's (fixed, 2 levels) impacts on the time to run around a particular track.

```{r runningExample, echo=TRUE}
# Load Running Data
running <- read.table(
  file = "http://stat.ethz.ch/~meier/teaching/data/running.dat", 
  header = TRUE
)

running$method <- as.factor(running$method)
running$drink <- as.factor(running$drink)

# Fit the anova model--same as usual
runningModel <- aov(
  formula = y ~ method*drink, # R interprets this as y ~ method + drink + method:drink
  data = running
)


# Type I Example
## From stats (base) R
anova(runningModel)

## Remember, we don't want raw output in a professional report

# Type II Example
car::Anova(
  mod = runningModel,
  type = 2
)

# Notice that the SSQ for Method is different in II than I

# Type III Example
car::Anova(
  mod = runningModel,
  type = 3
)

# Notice that the SSQ for Method and drink are different for III than in II and I


```

You will want to present the results in a much more professional way than what I have just done. (I'm just trying to show how you do the coding for different types of SSQs.)


\newpage

# Code Appendix

```{r codeAppendix, ref.label = knitr::all_labels(), echo = TRUE, eval = FALSE}

```